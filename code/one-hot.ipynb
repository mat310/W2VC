{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training word2vec modell\n",
      "training word2vec modell\n",
      "training word2vec modell\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import gensim\n",
    "import gzip\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "word2vec_modell = 'wanmei'\n",
    "Embsize = 150\n",
    "stride = 1\n",
    "Embepochs = 50\n",
    "kmer_len3 = 3\n",
    "kmer_len4 = 4\n",
    "kmer_len5 = 5\n",
    "\n",
    "def Gen_Words(sequences,kmer_len,s):\n",
    "\t\tout=[]\n",
    "\n",
    "\t\tfor i in sequences:\n",
    "\n",
    "\t\t\t\tkmer_list=[]\n",
    "\t\t\t\tfor j in range(0,(len(i)-kmer_len)+1,s):\n",
    "\n",
    "\t\t\t\t\t\t\tkmer_list.append(i[j:j+kmer_len])\n",
    "\n",
    "\t\t\t\tout.append(kmer_list)\n",
    "\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "\n",
    "def train(sequences,kmer_len):\n",
    "\tprint('training word2vec modell')\n",
    "\tdocument= Gen_Words(sequences,kmer_len,stride)\n",
    "\t#print(document)\n",
    "\tmodell = gensim.models.Word2Vec (document, window=int(12 / stride), min_count=0, size=Embsize,workers=multiprocessing.cpu_count())\n",
    "\tmodell.train(document,total_examples=len(document),epochs=Embepochs)\n",
    "\tmodell.save(word2vec_modell+str(kmer_len))\n",
    "\treturn document\n",
    "def read_fasta_file():\n",
    "    '''\n",
    "    used for load fasta data and transformd into numpy.array format\n",
    "    '''\n",
    "    fh = open('wanmei.txt', 'r')\n",
    "    seq = []\n",
    "    for line in fh:\n",
    "        if line.startswith('>'):\n",
    "            continue\n",
    "        else:\n",
    "            seq.append(line.replace('\\n', '').replace('\\r', ''))\n",
    "    fh.close()\n",
    "    matrix_data = np.array([list(e) for e in seq])\n",
    "    #print(matrix_data)\n",
    "    return seq\n",
    "\n",
    "sequences = read_fasta_file()\n",
    "document3=train(sequences,kmer_len3)\n",
    "document4=train(sequences,kmer_len4)\n",
    "document5=train(sequences,kmer_len5)\n",
    "\n",
    "model3 = gensim.models.Word2Vec.load(word2vec_modell+str(kmer_len3))\n",
    "model4 = gensim.models.Word2Vec.load(word2vec_modell+str(kmer_len4))\n",
    "model5 = gensim.models.Word2Vec.load(word2vec_modell+str(kmer_len5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35EB48>, 'CGT': <gensim.models.keyedvectors.Vocab object at 0x000001623C35EA08>, 'GTG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E988>, 'TGA': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E908>, 'GAG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E888>, 'AGC': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E808>, 'GCT': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E788>, 'CTG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E708>, 'GAT': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E688>, 'ATG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E608>, 'GAC': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E588>, 'ACT': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E508>, 'CTC': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E488>, 'TCA': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E408>, 'CAC': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E388>, 'ACA': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E308>, 'CTT': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E288>, 'TTA': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E208>, 'TAC': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E188>, 'CTA': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E108>, 'TAG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35E048>, 'AGG': <gensim.models.keyedvectors.Vocab object at 0x000001623C359C08>, 'GGC': <gensim.models.keyedvectors.Vocab object at 0x000001623C359E08>, 'GCA': <gensim.models.keyedvectors.Vocab object at 0x000001623C359E88>, 'CAT': <gensim.models.keyedvectors.Vocab object at 0x000001623C359FC8>, 'ATT': <gensim.models.keyedvectors.Vocab object at 0x000001623C359F48>, 'TTC': <gensim.models.keyedvectors.Vocab object at 0x000001623C359D08>, 'TCC': <gensim.models.keyedvectors.Vocab object at 0x000001623931F108>, 'CCT': <gensim.models.keyedvectors.Vocab object at 0x000001623931F248>, 'TCG': <gensim.models.keyedvectors.Vocab object at 0x000001623C3943C8>, 'GTT': <gensim.models.keyedvectors.Vocab object at 0x000001623C394148>, 'TTT': <gensim.models.keyedvectors.Vocab object at 0x000001623C3940C8>, 'ACC': <gensim.models.keyedvectors.Vocab object at 0x000001623C394048>, 'CCG': <gensim.models.keyedvectors.Vocab object at 0x000001623C394408>, 'CGA': <gensim.models.keyedvectors.Vocab object at 0x000001623C3947C8>, 'GTC': <gensim.models.keyedvectors.Vocab object at 0x000001623C394688>, 'GCG': <gensim.models.keyedvectors.Vocab object at 0x000001623C3944C8>, 'GTA': <gensim.models.keyedvectors.Vocab object at 0x000001623C394208>, 'TAA': <gensim.models.keyedvectors.Vocab object at 0x000001623C394748>, 'AAC': <gensim.models.keyedvectors.Vocab object at 0x000001623C3948C8>, 'AAA': <gensim.models.keyedvectors.Vocab object at 0x000001623C394448>, 'CGC': <gensim.models.keyedvectors.Vocab object at 0x000001623C394C08>, 'TGG': <gensim.models.keyedvectors.Vocab object at 0x000001623C394908>, 'GGT': <gensim.models.keyedvectors.Vocab object at 0x000001623C394AC8>, 'TCT': <gensim.models.keyedvectors.Vocab object at 0x000001623C394C88>, 'GAA': <gensim.models.keyedvectors.Vocab object at 0x000001623C394D08>, 'CAA': <gensim.models.keyedvectors.Vocab object at 0x000001623C394D88>, 'AAT': <gensim.models.keyedvectors.Vocab object at 0x000001623C394E08>, 'ATC': <gensim.models.keyedvectors.Vocab object at 0x000001623C394E88>, 'CAG': <gensim.models.keyedvectors.Vocab object at 0x000001623C394F08>, 'GGA': <gensim.models.keyedvectors.Vocab object at 0x000001623C394F88>, 'TTG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D048>, 'CGG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D0C8>, 'GGG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D148>, 'CCC': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D1C8>, 'CCA': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D248>, 'ATA': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D2C8>, 'AGT': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D348>, 'TGT': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D3C8>, 'TGC': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D448>, 'GCC': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D4C8>, 'AGA': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D548>, 'AAG': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D5C8>, 'TAT': <gensim.models.keyedvectors.Vocab object at 0x000001623C35D648>}\n"
     ]
    }
   ],
   "source": [
    "print(model3.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 150)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(model3.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACG', 'CGT', 'GTG', 'TGA', 'GAG', 'AGC', 'GCT', 'CTG', 'GAT', 'ATG', 'GAC', 'ACT', 'CTC', 'TCA', 'CAC', 'ACA', 'CTT', 'TTA', 'TAC', 'CTA', 'TAG', 'AGG', 'GGC', 'GCA', 'CAT', 'ATT', 'TTC', 'TCC', 'CCT', 'TCG', 'GTT', 'TTT', 'ACC', 'CCG', 'CGA', 'GTC', 'GCG', 'GTA', 'TAA', 'AAC', 'AAA', 'CGC', 'TGG', 'GGT', 'TCT', 'GAA', 'CAA', 'AAT', 'ATC', 'CAG', 'GGA', 'TTG', 'CGG', 'GGG', 'CCC', 'CCA', 'ATA', 'AGT', 'TGT', 'TGC', 'GCC', 'AGA', 'AAG', 'TAT']\n"
     ]
    }
   ],
   "source": [
    "print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {word: index for index, word in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACG': 0, 'CGT': 1, 'GTG': 2, 'TGA': 3, 'GAG': 4, 'AGC': 5, 'GCT': 6, 'CTG': 7, 'GAT': 8, 'ATG': 9, 'GAC': 10, 'ACT': 11, 'CTC': 12, 'TCA': 13, 'CAC': 14, 'ACA': 15, 'CTT': 16, 'TTA': 17, 'TAC': 18, 'CTA': 19, 'TAG': 20, 'AGG': 21, 'GGC': 22, 'GCA': 23, 'CAT': 24, 'ATT': 25, 'TTC': 26, 'TCC': 27, 'CCT': 28, 'TCG': 29, 'GTT': 30, 'TTT': 31, 'ACC': 32, 'CCG': 33, 'CGA': 34, 'GTC': 35, 'GCG': 36, 'GTA': 37, 'TAA': 38, 'AAC': 39, 'AAA': 40, 'CGC': 41, 'TGG': 42, 'GGT': 43, 'TCT': 44, 'GAA': 45, 'CAA': 46, 'AAT': 47, 'ATC': 48, 'CAG': 49, 'GGA': 50, 'TTG': 51, 'CGG': 52, 'GGG': 53, 'CCC': 54, 'CCA': 55, 'ATA': 56, 'AGT': 57, 'TGT': 58, 'TGC': 59, 'GCC': 60, 'AGA': 61, 'AAG': 62, 'TAT': 63}\n"
     ]
    }
   ],
   "source": [
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=np.zeros(shape=(len(sequences),41-kmer_len3+1,max(word_index.values())+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17808, 39, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,17808):\n",
    "\n",
    "#     for word in document3[i]:\n",
    "#         s.append(model3.wv[word])\n",
    "    \n",
    "    for j,word in list(enumerate(document3[i])):\n",
    "      #  s.append(model4.wv[word])\n",
    "        \n",
    "        index=word_index.get(word)\n",
    "\n",
    "        results[i,j,index]=1\n",
    "#     for word in document5[i]:\n",
    "#         s.append(model5.wv[word])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17808, 39, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#t_x=pd.read_csv('wanmeir.csv', header=None, index_col=None)\n",
    "t_y=pd.read_csv('w_Y.csv', header=None, index_col=None)\n",
    "\n",
    "xx= np.array(results)\n",
    "xx_y=t_y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11396, 39, 64) (3562, 39, 64) (2850, 39, 64)\n",
      "<keras.callbacks.callbacks.ReduceLROnPlateau object at 0x00000162859C2A48>\n",
      "Starting training \n",
      "Train on 11396 samples, validate on 2850 samples\n",
      "Epoch 1/15\n",
      "11396/11396 [==============================] - 9s 764us/step - loss: 0.3400 - accuracy: 0.8511 - val_loss: 0.2590 - val_accuracy: 0.9011\n",
      "Epoch 2/15\n",
      "11396/11396 [==============================] - 9s 753us/step - loss: 0.2542 - accuracy: 0.9008 - val_loss: 0.2494 - val_accuracy: 0.9067\n",
      "Epoch 3/15\n",
      "11396/11396 [==============================] - 10s 918us/step - loss: 0.2220 - accuracy: 0.9137 - val_loss: 0.2691 - val_accuracy: 0.9025\n",
      "Epoch 4/15\n",
      "11396/11396 [==============================] - 10s 869us/step - loss: 0.2040 - accuracy: 0.9217 - val_loss: 0.2530 - val_accuracy: 0.9116\n",
      "Epoch 5/15\n",
      "11396/11396 [==============================] - 10s 880us/step - loss: 0.1586 - accuracy: 0.9411 - val_loss: 0.2511 - val_accuracy: 0.9116\n",
      "Epoch 6/15\n",
      "11396/11396 [==============================] - 11s 935us/step - loss: 0.1471 - accuracy: 0.9486 - val_loss: 0.2569 - val_accuracy: 0.9098\n",
      "Epoch 7/15\n",
      "11396/11396 [==============================] - 11s 948us/step - loss: 0.1339 - accuracy: 0.9530 - val_loss: 0.2571 - val_accuracy: 0.9105\n",
      "Epoch 8/15\n",
      "11396/11396 [==============================] - 11s 949us/step - loss: 0.1327 - accuracy: 0.9534 - val_loss: 0.2571 - val_accuracy: 0.9105\n",
      "Epoch 9/15\n",
      "11396/11396 [==============================] - 11s 959us/step - loss: 0.1344 - accuracy: 0.9530 - val_loss: 0.2572 - val_accuracy: 0.9105\n",
      "Epoch 10/15\n",
      "11396/11396 [==============================] - 11s 951us/step - loss: 0.1327 - accuracy: 0.9533 - val_loss: 0.2573 - val_accuracy: 0.9105\n",
      "Epoch 11/15\n",
      "11396/11396 [==============================] - 11s 965us/step - loss: 0.1314 - accuracy: 0.9558 - val_loss: 0.2573 - val_accuracy: 0.9105\n",
      "Epoch 12/15\n",
      "11396/11396 [==============================] - 11s 982us/step - loss: 0.1298 - accuracy: 0.9551 - val_loss: 0.2573 - val_accuracy: 0.9105\n",
      "Epoch 13/15\n",
      "11396/11396 [==============================] - 11s 959us/step - loss: 0.1335 - accuracy: 0.9523 - val_loss: 0.2573 - val_accuracy: 0.9105\n",
      "Epoch 14/15\n",
      "11396/11396 [==============================] - 11s 983us/step - loss: 0.1289 - accuracy: 0.9550 - val_loss: 0.2573 - val_accuracy: 0.9105\n",
      "Epoch 15/15\n",
      "11396/11396 [==============================] - 11s 993us/step - loss: 0.1275 - accuracy: 0.9567 - val_loss: 0.2573 - val_accuracy: 0.9105\n",
      "Training finished \n",
      "\n",
      "3562/3562 [==============================] - 1s 285us/step\n",
      "Evaluation on test data: loss = 0.246893 accuracy = 91.41% \n",
      "\n",
      "调用函数auc： 0.9644302781366836\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 34, 128)           49280     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 29, 64)            49216     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 29, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 24, 32)            12320     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 12, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               38500     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 149,417\n",
      "Trainable params: 149,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "auc： 0.9644302781366836\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,GlobalAveragePooling1D\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score \n",
    "from keras.layers import TimeDistributed ,advanced_activations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras as K\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "nb_filter=32\n",
    "filter_length=6\n",
    "def creat_model():\n",
    "    global xx\n",
    "    init = K.initializers.glorot_uniform()\n",
    "    #scheduler = keras.callbacks.ReduceLROnPlateau(simple_adam, 'max', factor=0.5, patience=3)\n",
    "    model = K.models.Sequential()\n",
    "\n",
    "\n",
    "    #model.add(Convolution1D(nb_filter=64, filter_length=1, input_shape=(500, 10)))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dropout(0.4))\n",
    "    # 定义卷积层\n",
    "\n",
    "    # 编译模型\n",
    "    model = keras.Sequential()\n",
    "    acctivation=keras.layers.advanced_activations.LeakyReLU()  \n",
    "\n",
    "    model.add(Convolution1D(4*nb_filter, filter_length, strides=1, padding='valid'))\n",
    "#    model.add(keras.layers.MaxPool1D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution1D(2*nb_filter, filter_length, strides=1, padding='valid'))\n",
    "#    model.add(keras.layers.MaxPool1D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "\n",
    "    model.add(Dropout(0.2))    \n",
    "    model.add(Convolution1D(nb_filter, filter_length, strides=1, padding='valid'))\n",
    "    model.add(keras.layers.MaxPool1D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "#\n",
    "    model.add(Dropout(0.2)) \n",
    "#\n",
    "#   model.add(Convolution1D(4*nb_filter, filter_length, strides=1, padding='valid'))\n",
    "   # model.add(keras.layers.MaxPool1D(pool_size=2, strides=2, padding=\"valid\"))\n",
    "  #  model.add(Dropout(0.2))\n",
    "\n",
    " #   model.add(TimeDistributed(Dense(32)))\n",
    "#    model.add(keras.layers.LSTM(32, return_sequences=True))\n",
    "#    model.add(Bidirectional(LSTM(16, return_sequences=True)))\n",
    "\n",
    "#    model.add(CRF(32))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(K.layers.Dense(units=100 ,kernel_initializer=init, activation='relu'))\n",
    "   # model.add(Dropout(0.2))\n",
    "#    model.add(K.layers.Dense(units=1000 ,kernel_initializer=init, activation='relu'))\n",
    "   # model.add(Dropout(0.2))\n",
    "    model.add(K.layers.Dense(units=1, kernel_initializer=init, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(0.001),metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def train():\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=7)\n",
    "    for train, test in kfold.split(xx, xx_y):\n",
    "        train_x=xx[train]\n",
    "        train_y=xx_y[train]\n",
    "        test_x=xx[test]\n",
    "        test_y=xx_y[test]\n",
    "        train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "        print(train_x.shape,test_x.shape,val_x.shape)\n",
    "        model = creat_model()\n",
    "        max_epochs = 10\n",
    "        print(\"Starting training \")\n",
    "        h = model.fit(train_x, train_y, epochs=max_epochs, batch_size=128,shuffle=True, verbose=1,callbacks=[history],validation_data=(val_x, val_y))\n",
    "        print(\"Training finished \\n\")\n",
    "\n",
    "        eval = model.evaluate(test_x, test_y, verbose=1)\n",
    "        print(\"Evaluation on test data: loss = %0.6f accuracy = %0.2f%% \\n\" % (eval[0], eval[1] * 100) )\n",
    "        print(model.summary())\n",
    "\n",
    "def train2():\n",
    "    train_x, test_x, train_y, test_y = train_test_split(xx, xx_y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "    train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "    #train_x, val_x, train_y, val_y = train_test_split(xx, xx_y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "    print(train_x.shape,test_x.shape,val_x.shape)\n",
    "    model = creat_model()\n",
    "    max_epochs =15\n",
    "    \n",
    "    from keras.callbacks import ReduceLROnPlateau\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, mode='auto',factor=0.1)\n",
    "    print(reduce_lr)\n",
    "    print(\"Starting training \")\n",
    "    h = model.fit(train_x, train_y, epochs=max_epochs, batch_size=32,shuffle=True, verbose=1,callbacks=[reduce_lr,history],validation_data=(val_x, val_y))\n",
    "    print(\"Training finished \\n\")\n",
    "\n",
    "    scores = model.evaluate(test_x, test_y, verbose=1)\n",
    "    print(\"Evaluation on test data: loss = %0.6f accuracy = %0.2f%% \\n\" % (scores[0],scores[1] * 100) )\n",
    "    y_score = model.predict_proba(test_x)\n",
    "    print ('调用函数auc：', roc_auc_score(test_y, y_score))\n",
    "    print(model.summary())\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_y.ravel(),y_score.ravel())\n",
    "    aucc = auc(fpr, tpr)\n",
    "    print ('auc：', aucc)\n",
    "#     plt.figure()\n",
    "\n",
    "#     plt.rcParams['figure.dpi'] = 350\n",
    "#     plt.plot(fpr, tpr, c = 'r', lw = 2, alpha = 0.7, label = 'AUC=%.3f' % aucc)\n",
    "#     plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "#     plt.xlim((-0.01, 1.02))\n",
    "#     plt.ylim((-0.01, 1.02))\n",
    "#     plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "#     plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "#     plt.xlabel('False Positive Rate', fontsize=13)\n",
    "#     plt.ylabel('True Positive Rate', fontsize=13)\n",
    "#     plt.grid(b=True, ls=':')\n",
    "#     plt.legend(loc='lower right', fancybox=True, framealpha=0.8, fontsize=12)\n",
    "#     plt.title('AUC', fontsize=17)\n",
    "#     plt.show()\n",
    "  \n",
    "#    Z_K = model.predict(test_x)\n",
    "#    pd.DataFrame(Z_K).to_csv(str(eval[1] * 100)+'zzz_d.csv',header=None,index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    " #   train()\n",
    "    train2()\n",
    "    import winsound \n",
    "\n",
    "    duration = 1000  # millisecond\n",
    "    freq = 440  # Hz\n",
    "    winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax: 在多分类中常用的激活函数，是基于逻辑回归的。\n",
    "#softplus：softplus(x)=log(1+e^x)，近似生物神经激活函数，最近出现的。\n",
    "#Relu：近似生物神经激活函数，最近出现的。\n",
    "#tanh：双曲正切激活函数，也是很常用的。\n",
    "#sigmoid：S型曲线激活函数，最常用的。\n",
    "#hard_sigmoid：基于S型激活函数。\n",
    "#linear：线性激活函数，最简单的\n",
    "\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        pdf = PdfPages('x.pdf')\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.rcParams['figure.dpi'] = 350\n",
    "\n",
    "     # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"center right\")\n",
    "        plt.title('Acc-loss curve of AD_RFHCP')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "        pdf.close()\n",
    "        plt.show()\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
